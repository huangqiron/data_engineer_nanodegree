{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration Data Modeling and Implementation\n",
    "### Data Engineering Capstone Project\n",
    "#### Project Summary\n",
    "The project's goal is to build out an data pipeline that uses I94 immigratin data, city's population, temperature and airport data to create a data warehouse optimized for analyzing immigration events. The data warehouse can provide insight into the travellers' statistical information, like travel purpose and visa type, and factors affecting travellers' distribution, like number of airports in a city and average temperature of the month.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import re\n",
    "import string\n",
    "import configparser\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from pyspark.sql import SparkSession, DataFrame, Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf, col, length, year, month, max, min, mean, asc, desc, explode, row_number, when\n",
    "from pyspark.sql.types import StructType as Struct, StructField as Field, DoubleType as Double, DecimalType as Decimal, StringType as String, IntegerType as Int, LongType as Long, DateType as Date, TimestampType as Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "IMMIGRATION_FILE = config['FILE']['IMMIGRATION_FILE']\n",
    "IMMIGRATION_LABEL_FILE = config['FILE']['IMMIGRATION_LABEL_FILE']\n",
    "TEMPERATURE_FILE = config['FILE']['TEMPERATURE_FILE']\n",
    "AIRPORT_FILE = config['FILE']['AIRPORT_FILE']\n",
    "DEMOGRAPHICS_FILE = config['FILE']['DEMOGRAPHICS_FILE']\n",
    "CHUNK_SIZE = config['PREPROCESSING']['CHUNK_SIZE']\n",
    "AWS_KEY_ID = config['IAM']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_KEY = config['IAM']['AWS_SECRET_ACCESS_KEY']\n",
    "CLUSTER_ENDPOINT = config['REDSHIFT']['HOST']\n",
    "DATABASE_NAME = config['REDSHIFT']['DB_NAME']\n",
    "USER_NAME = config['REDSHIFT']['DB_USER']\n",
    "PASSWORD = config['REDSHIFT']['DB_PASSWORD']\n",
    "CLUSTER_PORT = config['REDSHIFT']['DB_PORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "                    .enableHiveSupport()\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### 1.1 Scope \n",
    "The target of this project is to create a data warehouse for analyzing international travellers's statistical distribution and factors that affect the distribution. Therefore, serveral dimension tables and one fact table will be created in a AWS Redshift cluster. There are four datasets, I94 Immigration data, US Demographic Data, Weather Data and Airport data. After investigation on the, a data model will be created according to the target. Then, a data pipeline will implement the ETL, including data extracing, cleaning, transforming and loading. In the end, a data quality check will be excuted to exmaine the ETL result. \n",
    "\n",
    "#### 1.2 Describe and Gather Data \n",
    "#### 1.2.1 Immigration Data\n",
    "This data comes from the US National Tourism and Trade Office. The link is https://travel.trade.gov/research/reports/i94/historical/2016.html. It is provided in SAS7BDAT format which is a binary database storage format. The data dictionary of immigration data is as follows,\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| CICID | Primary Key |\n",
    "| I94YR | Year |\n",
    "| I94MON | Month |\n",
    "| I94CIT | Country of Citizenship |\n",
    "| I94RES | Country of Residency |\n",
    "| I94PORT | Port of Arrival |\n",
    "| ARRDATE | Arrival Date |\n",
    "| I94MODE | Transportation Mode |\n",
    "| I94ADDR | State of Arrival |\n",
    "| DEPDATE | Departure Date |\n",
    "| I94BIR | Age|\n",
    "| I94VISA | Visa Category |\n",
    "| COUNT | Number of People |\n",
    "| DTADFILE | Character Date |\n",
    "| VISAPOST | Department Issuing Visa |\n",
    "| OCCUP | Occupation |\n",
    "| ENTDEPA | Arrival Flag |\n",
    "| ENTDEPD | Departure Flag |\n",
    "| ENTDEPU | Update Flag |\n",
    "| MATFLAG | Match Flag |\n",
    "| BIRYEAR | Year of Birth |\n",
    "| DTADDTO | Character Date |\n",
    "| GENDER | Gender |\n",
    "| INSNUM | INS number |\n",
    "| AIRLINE | Airline |\n",
    "| ADMNUM | Admission number |\n",
    "| FLTNO | Flight Number |\n",
    "| VISATYPE | Visa Type |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for root, dirs, files in os.walk(IMMIGRATION_FILE):\n",
    "    for file in files:\n",
    "        if file.endswith(\".sas7bdat\"):\n",
    "            file_list.append(os.path.join(root, file))      \n",
    "file = file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_spark_df = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "immigration_spark_df.printSchema()\n",
    "immigration_spark_df.show(5)\n",
    "immigration_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.2 Weather Data\n",
    "This data comes from Kaggle. The link is https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data. It is provided in CSV format and its data dictionary is as follow,\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| dt | Date |\n",
    "| AverageTemperature | Monthly Average Temperature |\n",
    "| AverageTemperatureUncertainty | Monthly Average Temperature Uncertainty |\n",
    "| City | City |\n",
    "| Country | Country |\n",
    "| Latitude | Latitude |\n",
    "| Longitude | Longitude |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_spark_df = spark.read.format('csv').option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(TEMPERATURE_FILE)\n",
    "weather_spark_df.printSchema()\n",
    "weather_spark_df.show(5)\n",
    "weather_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.3 US Demographic Data by City\n",
    "This data comes from OpenSoft. The link is https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/. It is provided in CSV format and its data dictionay is as follows,\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| City | City |\n",
    "| State | State |\n",
    "| Median Age | Median of Population Age |\n",
    "| Male Population | Population of Male Residents |\n",
    "| Female Population | Pouplation of Female Residents |\n",
    "| Total Population | Population of All Residents |\n",
    "| Number of Veterans | Population of Veterans |\n",
    "| Foreign-born | Population of Foreign-born Residents |\n",
    "| Average Household Size | Average of Household Size |\n",
    "| State Code | Two-letter State Code |\n",
    "| Race | Race |\n",
    "| Count | Population of Race |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_spark_df = spark.read.format('csv').option(\"sep\", \";\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(DEMOGRAPHICS_FILE)\n",
    "demographic_spark_df.printSchema()\n",
    "demographic_spark_df.show(5)\n",
    "demographic_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.4 Airport Data\n",
    "This data comes from datahub. The link is https://datahub.io/core/airport-codes#data. It is provided in CSV format and its data dictionary is as follows,\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| ident | Airport Identifier |\n",
    "| type | Type of Airport |\n",
    "| name | Name of Airport |\n",
    "| elevation_ft | Elevation of Airport in Feet |\n",
    "| continent | Continent of Airport |\n",
    "| iso_country | Country of Airport |\n",
    "| iso_region | Country and State of Airport |\n",
    "| municipality | City of Airport |\n",
    "| gps_code | GPS Code of Airport |\n",
    "| iata_code | IATA Code of Airport |\n",
    "| local_code | Local Code of Airport |\n",
    "| coordinates | Latidue and Longitude of Airport |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_spark_df = spark.read.format('csv').option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(AIRPORT_FILE)\n",
    "airport_spark_df.printSchema()\n",
    "airport_spark_df.show(5)\n",
    "airport_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Immigration Data\n",
    "Some columns in the immigration data have codes that needs to be tranlasted in to meaningful contents. The Immigration Data Lable file, from the US National Tourism and Trade Office, can be used to implement the translation. The file's link is https://travel.trade.gov/research/reports/i94/historical/2016.html. It is provided in SAS format. Also, after translation, the immigration data can be joined with other data. The script below reads the translation of five types of codes.\n",
    "1. Country\n",
    "2. Port of Arrival\n",
    "3. Transportation Mode\n",
    "4. Destination State\n",
    "5. Visa Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_list = []\n",
    "port_list = []\n",
    "mode_list = []\n",
    "address_list = []\n",
    "visa_list = []\n",
    "\n",
    "with open(IMMIGRATION_LABEL_FILE) as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    country_flag = False\n",
    "    port_flag = False\n",
    "    mode_flag = False\n",
    "    address_flag = False\n",
    "    visa_flag = False  \n",
    "\n",
    "    for i, line in enumerate(lines):        \n",
    "        if 'value i94cntyl' in line:            \n",
    "            country_flag = True\n",
    "            continue\n",
    "        elif 'value $i94prtl' in line:           \n",
    "            port_flag = True\n",
    "            continue\n",
    "        elif 'value i94model' in line:            \n",
    "            mode_flag = True\n",
    "            continue\n",
    "        elif 'value i94addrl' in line:            \n",
    "            address_flag = True\n",
    "            continue    \n",
    "        elif '/* I94VISA' in line:            \n",
    "            visa_flag = True\n",
    "            continue\n",
    "            \n",
    "        if country_flag == True:\n",
    "            if len(line.replace(';','').replace('\\n','').replace('\\'','').strip()) > 5:\n",
    "                pair = list(line.split('='))\n",
    "                dict = {}               \n",
    "                dict['code'] = int(pair[0].replace('\\'','').strip())\n",
    "                dict['country'] = string.capwords(pair[1].replace(';','').replace('\\n','').replace('\\'','').strip())\n",
    "                country_list.append(dict)            \n",
    "            if ';' in line:\n",
    "                country_flag = False\n",
    "            continue\n",
    "        elif port_flag == True:                      \n",
    "            if len(line.replace(';','').replace('\\n','').replace('\\'','').strip()) > 5:\n",
    "                pair = list(line.split('='))\n",
    "                addr = pair[1].split(',')\n",
    "                dict = {}\n",
    "                dict['code'] = pair[0].replace('\\'','').strip()                \n",
    "                if len(addr) > 1:\n",
    "                    dict['city'] = string.capwords(addr[0].replace(';','').replace('\\n','').replace('\\'','').strip())\n",
    "                    dict['state'] = addr[1].replace(';','').replace('\\n','').replace('\\'','').strip().upper()\n",
    "                elif 'Collapsed' in addr[0]:\n",
    "                    dict['city'] = addr[0][addr[0].find(\"(\")+1:addr[0].find(\")\")]\n",
    "                    dict['state'] = 'NA'\n",
    "                else:\n",
    "                    dict['city'] = addr[0].replace(';','').replace('\\n','').replace('\\'','').strip()\n",
    "                    dict['state'] = 'NA'\n",
    "                port_list.append(dict)            \n",
    "            if ';' in line:\n",
    "                port_flag = False\n",
    "            continue\n",
    "        elif mode_flag == True:\n",
    "            if len(line.replace(';','').replace('\\n','').replace('\\'','').strip()) > 5:\n",
    "                pair = list(line.split('='))\n",
    "                dict = {}\n",
    "                dict['code'] = int(pair[0].replace('\\'','').strip())\n",
    "                dict['transport_mode'] = string.capwords(pair[1].replace(';','').replace('\\n','').replace('\\'','').strip())\n",
    "                mode_list.append(dict)            \n",
    "            if ';' in line:\n",
    "                mode_flag = False\n",
    "            continue         \n",
    "        elif address_flag == True:\n",
    "            if len(line.replace(';','').replace('\\n','').replace('\\'','').strip()) > 5:\n",
    "                pair = list(line.split('='))\n",
    "                dict = {}\n",
    "                dict['code'] = pair[0].replace('\\'','').strip()\n",
    "                dict['state'] = string.capwords(pair[1].replace(';','').replace('\\n','').replace('\\'','').strip())\n",
    "                address_list.append(dict)            \n",
    "            if ';' in line:\n",
    "                address_flag = False\n",
    "            continue   \n",
    "        elif visa_flag == True:\n",
    "            if len(line.replace(';','').replace('\\n','').replace('\\'','').strip()) > 5:                \n",
    "                pair = list(line.split('='))\n",
    "                dict = {}\n",
    "                dict['code'] = int(pair[0].replace('\\'','').strip())\n",
    "                dict['visa_cat'] = string.capwords(pair[1].replace(';','').replace('\\n','').replace('\\'','').strip())\n",
    "                visa_list.append(dict)            \n",
    "            if '*/' in line:\n",
    "                visa_flag = False\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.1 Country Code\n",
    "The country codes are used in I94CIT and I94RES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "+----+--------------------+\n",
      "|code|             country|\n",
      "+----+--------------------+\n",
      "| 582|Mexico Air Sea, A...|\n",
      "| 236|         Afghanistan|\n",
      "| 101|             Albania|\n",
      "| 316|             Algeria|\n",
      "| 102|             Andorra|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_spark_df = spark.sparkContext.parallelize(country_list).map(lambda x: Row(**x)).toDF()\n",
    "country_spark_df.printSchema()\n",
    "country_spark_df.show(5)\n",
    "country_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.2 Port Code\n",
    "The port codes are composed of states and cities in the I94PORT column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "+--------------------+----+-----+\n",
      "|                city|code|state|\n",
      "+--------------------+----+-----+\n",
      "|               Alcan| ALC|   AK|\n",
      "|           Anchorage| ANC|   AK|\n",
      "|Baker Aaf - Baker...| BAR|   AK|\n",
      "|       Daltons Cache| DAC|   AK|\n",
      "|Dew Station Pt La...| PIZ|   AK|\n",
      "+--------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_spark_df = spark.sparkContext.parallelize(port_list).map(lambda x: Row(**x)).toDF()\n",
    "port_spark_df = port_spark_df\n",
    "port_spark_df.printSchema()\n",
    "port_spark_df.show(5)\n",
    "port_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.3 Transportation Mode Code\n",
    "The transportation mode codes are used in I94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- transport_mode: string (nullable = true)\n",
      "\n",
      "+----+--------------+\n",
      "|code|transport_mode|\n",
      "+----+--------------+\n",
      "|   1|           Air|\n",
      "|   2|           Sea|\n",
      "|   3|          Land|\n",
      "|   9|  Not Reported|\n",
      "+----+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_spark_df = spark.sparkContext.parallelize(mode_list).map(lambda x: Row(**x)).toDF()\n",
    "mode_spark_df.printSchema()\n",
    "mode_spark_df.show(5)\n",
    "mode_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.4 Address Code\n",
    "The address codes are used in I94ADDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "+----+----------+\n",
      "|code|     state|\n",
      "+----+----------+\n",
      "|  AL|   Alabama|\n",
      "|  AK|    Alaska|\n",
      "|  AZ|   Arizona|\n",
      "|  AR|  Arkansas|\n",
      "|  CA|California|\n",
      "+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_spark_df = spark.sparkContext.parallelize(address_list).map(lambda x: Row(**x)).toDF()\n",
    "address_spark_df.printSchema()\n",
    "address_spark_df.show(5)\n",
    "address_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.5 Visa Code\n",
    "The visa codes are used in I94VISA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- visa_cat: string (nullable = true)\n",
      "\n",
      "+----+--------+\n",
      "|code|visa_cat|\n",
      "+----+--------+\n",
      "|   1|Business|\n",
      "|   2|Pleasure|\n",
      "|   3| Student|\n",
      "+----+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_spark_df = spark.sparkContext.parallelize(visa_list).map(lambda x: Row(**x)).toDF()\n",
    "visa_spark_df.printSchema()\n",
    "visa_spark_df.show(5)\n",
    "visa_spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.6 The cleaning of immigration data includes three steps:\n",
    "1. The data has many unrelated data, so the first step is to remove them. \n",
    "2. The next step is translating the types of code into readable contents using the data extract from lable description file. \n",
    "3. Since this project focuses on the statistics of immigration data related to airports, only the records whose trasportation mode are air is kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_immigration_df = immigration_spark_df.select(col('cicid').cast(Int()),col('i94yr').cast(Int()).alias('year'), col('i94mon').cast(Int()).alias('month'), col('i94cit').alias('citizenship'),\\\n",
    "                                                     col('i94res').alias('residency'), col('i94port').alias('port'), col('i94mode').alias('transportation_mode'), col('i94addr').alias('arrival_state'),\\\n",
    "                                                     col('i94bir').cast(Int()).alias('age'), col('i94visa').alias('visa_category'),col('visatype').alias('visa_type'), col('biryear').cast(Int()).alias('birth_year'))\\\n",
    "                                             .join(country_spark_df, col('citizenship')==country_spark_df.code, how='left').withColumn('citizenship',col('country')).drop('code','country')\\\n",
    "                                             .join(country_spark_df, col('residency')==country_spark_df.code, how='left').withColumn('residency',col('country')).drop('code','country')\\\n",
    "                                             .join(port_spark_df, col('port')==port_spark_df.code, how='left').withColumn('port_city',col('city')).withColumn('port_state',col('state')).drop('code','city','state')\\\n",
    "                                             .join(mode_spark_df, col('transportation_mode')==mode_spark_df.code, how='left').withColumn('transportation_mode',col('transport_mode')).drop('code','transport_mode')\\\n",
    "                                             .join(address_spark_df, col('arrival_state')==address_spark_df.code, how='left').withColumn('arrival_state',col('state')).drop('code','state')\\\n",
    "                                             .join(visa_spark_df, col('visa_category')==visa_spark_df.code, how='left').withColumn('visa_category',col('visa_cat')).drop('code','visa_cat')\\\n",
    "                                             .withColumn('port_state', when(col('port_city')=='WASHINGTON DC', 'DC').otherwise(col('port_state')))\\\n",
    "                                             .withColumn('port_city', when(col('port_city')=='WASHINGTON DC', 'Washington').otherwise(col('port_city')))\\\n",
    "                                             .filter(col('transportation_mode')=='Air').orderBy(asc('cicid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- citizenship: string (nullable = true)\n",
      " |-- residency: string (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- transportation_mode: string (nullable = true)\n",
      " |-- arrival_state: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa_category: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- port_city: string (nullable = true)\n",
      " |-- port_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_immigration_df.printSchema()\n",
    "cleaned_immigration_df.show(5)\n",
    "cleaned_immigration_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Weather Data\n",
    "The data has the monthly average temperature of cities each year from 1850 to 2013. But the date of interest is from 01/01/2016 to 12/31/2016, so I calculated the monthly average temperature of cities over years. Plus, I'm interested in the cities in United States, so only records of cities in United States are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_weather_df = weather_spark_df.filter(col('Country') == 'United States')\\\n",
    "                    .select(month('dt').alias('month'), col('AverageTemperature').alias('temperature'), col('City').alias('city'), col('Country').alias('country'))\\\n",
    "                    .groupBy('country', 'city', 'month').agg(mean('temperature').cast(Decimal(5,2)).alias('average_temperature')).orderBy(asc('city'), asc('month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_weather_df.printSchema()\n",
    "cleaned_weather_df.show(20)\n",
    "cleaned_weather_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.3 US Demographic Data by City\n",
    "The US demographic data is pretty clean. But it has one issue that there are duplicates due to muliple races in one city, so the only cleaning step is to remove the duplicate cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_demographic_df = demographic_spark_df.select(col('State Code').alias('state_code'), col('State').alias('state'), col('City').alias('city'), col('Median Age').alias('median_age'),\\\n",
    "                                                     col('Male Population').alias('male_population'), col('Female Population').alias('female_population'), col('Total Population').alias('total_population'),\\\n",
    "                                                     col('Number of Veterans').alias('veteran_population'), col('Average Household Size').alias('average_household_size')).dropDuplicates().orderBy(asc('state_code'),asc('city'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_demographic_df.printSchema()\n",
    "cleaned_demographic_df.show(5)\n",
    "cleaned_demographic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.4 Airport Data\n",
    "The airport data includes airport information around the world. But the conuntry of interest is United States, so airports not in United States are removed. Second, the state name is part of iso_region, in order to get the state where the airports are located in, I applied a function to_state to the iso_region column. Besides, the latitude and longitude of airports are stored in the coordinates column, I used two functions to_latitude and to_longitude to split the coordinates into latitude and longitude. Third, some airports have no city value that is used for immigration data to find correpsonding airports, therefore, only airports whose city column is not null are kept. Last, heliports and Air Force bases are includes in the airport data, which have nothing to do with immigration and thus are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "to_latitude = udf(lambda x: float(x.split(',')[0]), Double())\n",
    "to_longitude = udf(lambda x: float(x.split(',')[1]), Double())\n",
    "to_state = udf(lambda x: x.split('-')[1], String())\n",
    "cleaned_airport_df = airport_spark_df.filter((col('iso_country') == 'US') & (col('municipality').isNotNull()) & (col('type').like('%airport%')) & (~col('name').like('%base%')) )\\\n",
    "                                     .withColumn('latitude', to_latitude('coordinates').cast(Decimal(9,6))).withColumn('longitude', to_longitude('coordinates').cast(Decimal(9,6))).withColumn('state', to_state('iso_region'))\\\n",
    "                                     .select(col('ident').alias('id'), col('type'), col('name'), col('elevation_ft'), col('iso_country').alias('country'), col('state'),\\\n",
    "                                             col('municipality').alias('city'), col('gps_code'), col('local_code'), col('latitude'),col('longitude'))\\\n",
    "                                     .orderBy(asc('state'), asc('city'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_airport_df.printSchema()\n",
    "cleaned_airport_df.show(20)\n",
    "cleaned_airport_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "1. Project Scope:\n",
    "This project is used to analysis the immigration distribution over city, temperature, traveller's citizenship, residency, visa category and visa type. Therefore, the immigration data will be used in the fact table factImmigration, and other descriptive information will be used in dimension tables, like dimCity and dimCountry.\n",
    "2. Granularity:\n",
    "Since the immigration data is provided in different month across cities, the granularity of fact and dimension tables is per month and per city.\n",
    "3. Fact Table:\n",
    "The factImmigration has the traveller's information, such as port, citizenship, residency, destination, visa category, visa type and arrvial date. \n",
    "4. Dimension Table:\n",
    "There are seven dimension tables, dimCountry, dimState, dimCity, dimTemperature, dimAirport, dimVisaCategory and dimVisaType. Dimension tables will be used to dissect the factImmigration to provide statistical analysis for the immigration data.\n",
    "5. Schema:\n",
    "The snowflake schema is adopted. For example, dimState is used to identify the cities in dimCity. The snowflake schema has some nomorlized dimensions so that it can reduce the data redundancy. But normlized data means joins will be used in some scenarions and thus slow the query execution. It's a trade off between storage efficiency and query performance.\n",
    "6. ER Diagram:\n",
    "The ER diagram of the date model is as follows,\n",
    "<img src=\"src/ER Diagram.png\">\n",
    "\n",
    "#### 3.2 Data Mapping\n",
    "The data mapping between files and tables will be explained for each table.\n",
    "##### 3.2.1 dimState\n",
    "The state information comes from the us-cities-demographics.csv. The id column is auto incremental. The mapping between the file and dimState is as follows,\n",
    "\n",
    "| us-cities-demographics | dimState |\n",
    "| :--- | :--- |\n",
    "| State | name |\n",
    "| State Code | state_code |\n",
    "\n",
    "##### 3.2.2 dimCity\n",
    "The city information comes from the us-cities-demographics.csv and dimState. The id column is auto incremental. The mapping between the file and dimCity is as follows,\n",
    "\n",
    "| us-cities-demographics | dimState | dimCity |\n",
    "| :--- | :--- | :--- |\n",
    "|  | id | state_id |\n",
    "| City | | name |\n",
    "| Median Age | | median_age |\n",
    "| Male Population | | male_population |\n",
    "| Female Population | | female_population |\n",
    "| Total Population | | total_population |\n",
    "| Number of Veterans | | veteran_population |\n",
    "| Average Household Size | | average_household_size |\n",
    "\n",
    "##### 3.2.3 dimAirport\n",
    "The airport information comes from the airport-codes_csv.csv and dimCity. The id column is auto incremental. The mapping between the file and dimAirport is as follows,\n",
    "\n",
    "| airport-codes_csv | dimCity | dimAirport |\n",
    "| :--- | :--- | :--- |\n",
    "|  | id | city_id |\n",
    "| name | | name |\n",
    "| elevation_ft | | elevation |\n",
    "| type | | type |\n",
    "| ident | | id_code |\n",
    "| gps_code | | gps_code |\n",
    "| local_code | | local_code |\n",
    "| coordinates | | latitude |\n",
    "| coordinates | | longitude |\n",
    "\n",
    "##### 3.2.4 dimTemperature\n",
    "The temperature information of each city comes from the GlobalLandTemperaturesByCity.csv and dimCity. The id column is auto incremental. The mapping between the file and dimTemperature is as follows,\n",
    "\n",
    "| GlobalLandTemperaturesByCity | dimCity | dimAirport |\n",
    "| :--- | :--- | :--- |\n",
    "|  | id | city_id |\n",
    "| dt | | month |\n",
    "| AverageTemperature | | temperature |\n",
    "\n",
    "##### 3.2.5 dimCountry\n",
    "The country information comes from the immigration .sas7bdat files and I94_SAS_Labels_Descriptions.SAS. The id column is auto incremental. The country name is identified by 94_SAS_Labels_Descriptions.SAS tranlateing I94CIT/I94RES in the .sas7bdat files,\n",
    "\n",
    "| \\*.sas7bdat | I94_SAS_Labels_Descriptions | dimCountry |\n",
    "| :--- | :--- | :--- |\n",
    "| I94CIT/I94RES | translation | name |\n",
    "\n",
    "##### 3.2.6 dimVisaCategory\n",
    "The visa category information comes from the immigration .sas7bdat files and I94_SAS_Labels_Descriptions.SAS. The id column is auto incremental. The visa category is identified by 94_SAS_Labels_Descriptions.SAS tranlateing I94VISA in the .sas7bdat files,\n",
    "\n",
    "| \\*.sas7bdat | I94_SAS_Labels_Descriptions | dimVisaCategory |\n",
    "| :--- | :--- | :--- |\n",
    "| I94VISA | translation | visa_category |\n",
    "\n",
    "##### 3.2.7 dimVisaType\n",
    "The visa type information comes from the immigration .sas7bdat files and I94_SAS_Labels_Descriptions.SAS. The id column is auto incremental. The visa type is identified by 94_SAS_Labels_Descriptions.SAS tranlateing VISATYPE in the .sas7bdat files,\n",
    "\n",
    "| \\*.sas7bdat | I94_SAS_Labels_Descriptions | dimVisaType |\n",
    "| :--- | :--- | :--- |\n",
    "| VISATYPE | translation | visa_type |\n",
    "\n",
    "##### 3.2.8 factImmigration\n",
    "The immigration information comes from the immigration .sas7bdat files and dimension tables. The id column is auto incremental. The mapping between the file and factImmigration is as follows,\n",
    "\n",
    "| \\*.sas7bdat | dimCountry | dimState | dimCity | dimVisaCategory | dimVisaType | factImmigration |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "|  |  |  | id |  |  | city_id |\n",
    "|  | id |  |  |  |  | citizenship |\n",
    "|  | id |  |  |  |  | residency |\n",
    "|  |  | id |  |  |  | destination |\n",
    "| CICID |  |  |  |  |  | cicid |\n",
    "|  |  |  |  | id |  | visa_cat_id |\n",
    "|  |  |  |  |  | id | visa_type_id |\n",
    "| I94YR |  |  |  |  |  | year |\n",
    "| I94MON |  |  |  |  |  | month |\n",
    "| BIRYEAR |  |  |  |  |  | birth_year |\n",
    "| I94BIR |  |  |  |  |  | age |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1 Create Tables\n",
    "The fact and dimension tables from the ER diagram are created on AWS Redshift cluster. The integrity contraints, such as primary key and foreign key, are applied to each table. After the tables are created, the queries for counting the number of rows are executed to check if the table are created successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimState has 0 rows.\n",
      "The dimCity has 0 rows.\n",
      "The dimTemperature has 0 rows.\n",
      "The dimAirport has 0 rows.\n",
      "The dimCountry has 0 rows.\n",
      "The dimVisaCategory has 0 rows.\n",
      "The dimVisaType has 0 rows.\n",
      "The factImmigration has 0 rows.\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(f\"host={CLUSTER_ENDPOINT} dbname={DATABASE_NAME} user={USER_NAME} password={PASSWORD} port={CLUSTER_PORT}\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "dimState_drop = (\"DROP TABLE IF EXISTS dimState\")\n",
    "dimCity_drop = (\"DROP TABLE IF EXISTS dimCity\")\n",
    "dimTemperature_drop = (\"DROP TABLE IF EXISTS dimTemperature\")\n",
    "dimAirport_drop = (\"DROP TABLE IF EXISTS dimAirport\")\n",
    "dimCountry_drop = (\"DROP TABLE IF EXISTS dimCountry\")\n",
    "dimVisaCategory_drop = (\"DROP TABLE IF EXISTS dimVisaCategory\")\n",
    "dimVisaType_drop = (\"DROP TABLE IF EXISTS dimVisaType\")\n",
    "factImmigration_drop = (\"DROP TABLE IF EXISTS factImmigration\")\n",
    "\n",
    "dimState_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimState (\n",
    "                                                          id bigint NOT NULL PRIMARY KEY,                                                          \n",
    "                                                          name varchar,\n",
    "                                                          state_code varchar\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimCity_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimCity (\n",
    "                                                          id bigint NOT NULL PRIMARY KEY,\n",
    "                                                          state_id bigint,\n",
    "                                                          name varchar,\n",
    "                                                          median_age float,\n",
    "                                                          male_population bigint,\n",
    "                                                          female_population bigint,\n",
    "                                                          total_population bigint,\n",
    "                                                          veteran_population bigint,\n",
    "                                                          average_household_size float,\n",
    "                                                          FOREIGN KEY (state_id) REFERENCES dimState(id)\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimTemperature_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimTemperature (\n",
    "                                                          city_id bigint NOT NULL,                                                          \n",
    "                                                          month int,\n",
    "                                                          temperature float,\n",
    "                                                          PRIMARY KEY (city_id, month),\n",
    "                                                          FOREIGN KEY(city_id) REFERENCES dimCity(id)\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimAirport_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimAirport (\n",
    "                                                          id bigint NOT NULL PRIMARY KEY,\n",
    "                                                          city_id bigint,\n",
    "                                                          name varchar,\n",
    "                                                          elevation int,\n",
    "                                                          type varchar,\n",
    "                                                          id_code varchar,\n",
    "                                                          gps_code varchar,\n",
    "                                                          local_code varchar,\n",
    "                                                          latitude float,\n",
    "                                                          longitude float,\n",
    "                                                          FOREIGN KEY(city_id) REFERENCES dimCity(id)\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimCountry_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimCountry (\n",
    "                                                          id int NOT NULL PRIMARY KEY,                                                          \n",
    "                                                          name varchar\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimVisaCategory_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimVisaCategory (\n",
    "                                                          id int NOT NULL PRIMARY KEY,                                                          \n",
    "                                                          visa_category varchar\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimVisaType_create = (\"\"\"CREATE TABLE IF NOT EXISTS dimVisaType (\n",
    "                                                          id int NOT NULL PRIMARY KEY,                                                          \n",
    "                                                          visa_type varchar\n",
    "                                                          )\"\"\")\n",
    "\n",
    "factImmigration_create = (\"\"\"CREATE TABLE IF NOT EXISTS factImmigration (\n",
    "                                                          id bigint  NOT NULL PRIMARY KEY,\n",
    "                                                          city_id bigint,\n",
    "                                                          citizenship int,\n",
    "                                                          residency int,\n",
    "                                                          destination int,\n",
    "                                                          cicid bigint,\n",
    "                                                          visa_cat_id int,\n",
    "                                                          visa_type_id int,\n",
    "                                                          year int,\n",
    "                                                          month int,\n",
    "                                                          birth_year int, \n",
    "                                                          age int,\n",
    "                                                          FOREIGN KEY(city_id) REFERENCES dimCity(id),\n",
    "                                                          FOREIGN KEY(citizenship) REFERENCES dimCountry(id),\n",
    "                                                          FOREIGN KEY(residency) REFERENCES dimCountry(id),\n",
    "                                                          FOREIGN KEY(destination) REFERENCES dimState(id),\n",
    "                                                          FOREIGN KEY(visa_cat_id) REFERENCES dimVisaCategory(id),\n",
    "                                                          FOREIGN KEY(visa_type_id) REFERENCES dimVisaType(id)\n",
    "                                                          )\"\"\")\n",
    "\n",
    "dimState_count = (\"SELECT 'dimState' AS table_name, COUNT(1) as num_of_records FROM dimstate\")\n",
    "dimCity_count = (\"SELECT 'dimCity' AS table_name, COUNT(1) as num_of_records FROM dimcity\")\n",
    "dimTemperature_count = (\"SELECT 'dimTemperature' AS table_name, COUNT(1) as num_of_records FROM dimtemperature\")\n",
    "dimAirport_count = (\"SELECT 'dimAirport' AS table_name, COUNT(1) as num_of_records FROM dimairport\")\n",
    "dimCountry_count = (\"SELECT 'dimCountry' AS table_name, COUNT(1) as num_of_records FROM dimcountry\")\n",
    "dimVisaCategory_count = (\"SELECT 'dimVisaCategory' AS table_name, COUNT(1) as num_of_records FROM dimvisacategory\")\n",
    "dimVisaType_count  = (\"SELECT 'dimVisaType' AS table_name, COUNT(1) as num_of_records FROM dimvisatype\")\n",
    "factImmigration_count = (\"SELECT 'factImmigration' AS table_name, COUNT(1) as num_of_records FROM factimmigration\")\n",
    "\n",
    "table_drop_list = [factImmigration_drop, dimVisaType_drop, dimVisaCategory_drop, dimCountry_drop, dimAirport_drop, dimTemperature_drop, dimCity_drop, dimState_drop]\n",
    "table_create_list = [dimState_create, dimCity_create, dimTemperature_create, dimAirport_create, dimCountry_create, dimVisaCategory_create, dimVisaType_create, factImmigration_create]\n",
    "table_count_list = [dimState_count, dimCity_count, dimTemperature_count, dimAirport_count, dimCountry_count, dimVisaCategory_count, dimVisaType_count, factImmigration_count]\n",
    "\n",
    "for query in table_drop_list:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "\n",
    "for query in table_create_list:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "    \n",
    "for query in table_count_list:\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchone()\n",
    "    print(f\"The {result[0]} has {result[1]} rows.\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Prepare the Dateframe to storage \n",
    "For each table, a pandas dataframe is created with same column names as the target table. Besides, an id column as surrogate key is added to each dataframe. The reason why I chose pandas dataframe as the staging tables is I can not install the spark-redshift package which can use spark to populate tables on the Redshift cluster. In the end, I used pandas together with SqlAlchemey to finish saving data to Redshift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>DE</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name state_code  id\n",
       "0               Alabama         AL   1\n",
       "1                Alaska         AK   2\n",
       "2               Arizona         AZ   3\n",
       "3              Arkansas         AR   4\n",
       "4            California         CA   5\n",
       "5              Colorado         CO   6\n",
       "6           Connecticut         CT   7\n",
       "7              Delaware         DE   8\n",
       "8  District of Columbia         DC   9\n",
       "9               Florida         FL  10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create datafrome to populate dimState\n",
    "state_winwdow = Window().orderBy('name')\n",
    "dimState_df = cleaned_demographic_df.select(col('state').alias('name'),'state_code').dropDuplicates().withColumn('id', row_number().over(state_winwdow))\n",
    "dimState_pd_df = dimState_df.toPandas()\n",
    "dimState_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>name</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>veteran_population</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>35.6</td>\n",
       "      <td>102122.0</td>\n",
       "      <td>112789.0</td>\n",
       "      <td>214911</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dothan</td>\n",
       "      <td>38.9</td>\n",
       "      <td>32172.0</td>\n",
       "      <td>35364.0</td>\n",
       "      <td>67536</td>\n",
       "      <td>6334.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hoover</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>38.1</td>\n",
       "      <td>91764.0</td>\n",
       "      <td>97350.0</td>\n",
       "      <td>189114</td>\n",
       "      <td>16637.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>38.0</td>\n",
       "      <td>91275.0</td>\n",
       "      <td>103030.0</td>\n",
       "      <td>194305</td>\n",
       "      <td>11939.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>35.4</td>\n",
       "      <td>94582.0</td>\n",
       "      <td>106004.0</td>\n",
       "      <td>200586</td>\n",
       "      <td>14955.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>29.1</td>\n",
       "      <td>47293.0</td>\n",
       "      <td>51045.0</td>\n",
       "      <td>98338</td>\n",
       "      <td>3647.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>32.2</td>\n",
       "      <td>152945.0</td>\n",
       "      <td>145750.0</td>\n",
       "      <td>298695</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Avondale</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712.0</td>\n",
       "      <td>41971.0</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Casas Adobes</td>\n",
       "      <td>44.8</td>\n",
       "      <td>30890.0</td>\n",
       "      <td>34375.0</td>\n",
       "      <td>65265</td>\n",
       "      <td>6601.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_id          name  median_age  male_population  female_population  \\\n",
       "0         1    Birmingham        35.6         102122.0           112789.0   \n",
       "1         1        Dothan        38.9          32172.0            35364.0   \n",
       "2         1        Hoover        38.5          38040.0            46799.0   \n",
       "3         1    Huntsville        38.1          91764.0            97350.0   \n",
       "4         1        Mobile        38.0          91275.0           103030.0   \n",
       "5         1    Montgomery        35.4          94582.0           106004.0   \n",
       "6         1    Tuscaloosa        29.1          47293.0            51045.0   \n",
       "7         2     Anchorage        32.2         152945.0           145750.0   \n",
       "8         3      Avondale        29.1          38712.0            41971.0   \n",
       "9         3  Casas Adobes        44.8          30890.0            34375.0   \n",
       "\n",
       "   total_population  veteran_population  average_household_size  id  \n",
       "0            214911             13212.0                    2.21   1  \n",
       "1             67536              6334.0                    2.59   2  \n",
       "2             84839              4819.0                    2.58   3  \n",
       "3            189114             16637.0                    2.18   4  \n",
       "4            194305             11939.0                    2.40   5  \n",
       "5            200586             14955.0                    2.41   6  \n",
       "6             98338              3647.0                    2.67   7  \n",
       "7            298695             27492.0                    2.77   8  \n",
       "8             80683              4815.0                    3.18   9  \n",
       "9             65265              6601.0                    2.24  10  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate dimCity\n",
    "city_window = Window().orderBy(asc('state_id'),asc('name'))\n",
    "dimCity_df = cleaned_demographic_df.join(dimState_df, cleaned_demographic_df.state==dimState_df.name, how='inner')\\\n",
    "                                .select(col('id').alias('state_id'), col('city').alias('name'), 'median_age', 'male_population',\\\n",
    "                                        'female_population', 'total_population', 'veteran_population', 'average_household_size')\\\n",
    "                                .withColumn('id', row_number().over(city_window))\n",
    "dimCity_pd_df = dimCity_df.toPandas()\n",
    "dimCity_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>month</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>23.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id  month temperature\n",
       "0        1      1        7.02\n",
       "1        1      2        8.92\n",
       "2        1      3       12.66\n",
       "3        1      4       17.08\n",
       "4        1      5       21.56\n",
       "5        1      6       25.37\n",
       "6        1      7       26.87\n",
       "7        1      8       26.50\n",
       "8        1      9       23.38\n",
       "9        1     10       17.09"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate dimTemperature\n",
    "dimTemperature_df = cleaned_weather_df.join(dimCity_df, cleaned_weather_df.city==dimCity_df.name, how='inner')\\\n",
    "                                .select(col('id').alias('city_id'), 'month', col('average_temperature').alias('temperature'))\\\n",
    "                                .orderBy(asc('city_id'),asc('month'))                                                                       \n",
    "dimTemperature_pd_df = dimTemperature_df.toPandas()\n",
    "dimTemperature_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation</th>\n",
       "      <th>type</th>\n",
       "      <th>id_code</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Birmingham-Shuttlesworth International Airport</td>\n",
       "      <td>650.0</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>KBHM</td>\n",
       "      <td>KBHM</td>\n",
       "      <td>BHM</td>\n",
       "      <td>-86.753502</td>\n",
       "      <td>33.562901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bonham Airport</td>\n",
       "      <td>600.0</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>AL40</td>\n",
       "      <td>AL40</td>\n",
       "      <td>AL40</td>\n",
       "      <td>-86.985802</td>\n",
       "      <td>33.543201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dothan Regional Airport</td>\n",
       "      <td>401.0</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KDHN</td>\n",
       "      <td>KDHN</td>\n",
       "      <td>DHN</td>\n",
       "      <td>-85.449600</td>\n",
       "      <td>31.321301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Madison County Executive Airport-Tom Sharp Jr ...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>KMDQ</td>\n",
       "      <td>KMDQ</td>\n",
       "      <td>MDQ</td>\n",
       "      <td>-86.557503</td>\n",
       "      <td>34.861401</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Huntsville International Carl T Jones Field</td>\n",
       "      <td>629.0</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>KHSV</td>\n",
       "      <td>KHSV</td>\n",
       "      <td>HSV</td>\n",
       "      <td>-86.775101</td>\n",
       "      <td>34.637199</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Big Sky Airport</td>\n",
       "      <td>830.0</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>AL93</td>\n",
       "      <td>AL93</td>\n",
       "      <td>AL93</td>\n",
       "      <td>-86.709999</td>\n",
       "      <td>34.885601</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Milton Airport</td>\n",
       "      <td>639.0</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>4AL8</td>\n",
       "      <td>4AL8</td>\n",
       "      <td>4AL8</td>\n",
       "      <td>-86.673302</td>\n",
       "      <td>34.490601</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Moontown Airport</td>\n",
       "      <td>650.0</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>3M5</td>\n",
       "      <td>3M5</td>\n",
       "      <td>3M5</td>\n",
       "      <td>-86.461403</td>\n",
       "      <td>34.747299</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Mobile Regional Airport</td>\n",
       "      <td>219.0</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>KMOB</td>\n",
       "      <td>KMOB</td>\n",
       "      <td>MOB</td>\n",
       "      <td>-88.242798</td>\n",
       "      <td>30.691200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Mobile Downtown Airport</td>\n",
       "      <td>26.0</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KBFM</td>\n",
       "      <td>KBFM</td>\n",
       "      <td>BFM</td>\n",
       "      <td>-88.068100</td>\n",
       "      <td>30.626801</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id                                               name  elevation  \\\n",
       "0        1     Birmingham-Shuttlesworth International Airport      650.0   \n",
       "1        1                                     Bonham Airport      600.0   \n",
       "2        2                            Dothan Regional Airport      401.0   \n",
       "3        4  Madison County Executive Airport-Tom Sharp Jr ...      756.0   \n",
       "4        4        Huntsville International Carl T Jones Field      629.0   \n",
       "5        4                                    Big Sky Airport      830.0   \n",
       "6        4                                     Milton Airport      639.0   \n",
       "7        4                                   Moontown Airport      650.0   \n",
       "8        5                            Mobile Regional Airport      219.0   \n",
       "9        5                            Mobile Downtown Airport       26.0   \n",
       "\n",
       "             type id_code gps_code local_code    latitude  longitude  id  \n",
       "0   large_airport    KBHM     KBHM        BHM  -86.753502  33.562901   1  \n",
       "1   small_airport    AL40     AL40       AL40  -86.985802  33.543201   2  \n",
       "2  medium_airport    KDHN     KDHN        DHN  -85.449600  31.321301   3  \n",
       "3   small_airport    KMDQ     KMDQ        MDQ  -86.557503  34.861401   4  \n",
       "4   large_airport    KHSV     KHSV        HSV  -86.775101  34.637199   5  \n",
       "5   small_airport    AL93     AL93       AL93  -86.709999  34.885601   6  \n",
       "6   small_airport    4AL8     4AL8       4AL8  -86.673302  34.490601   7  \n",
       "7   small_airport     3M5      3M5        3M5  -86.461403  34.747299   8  \n",
       "8   large_airport    KMOB     KMOB        MOB  -88.242798  30.691200   9  \n",
       "9  medium_airport    KBFM     KBFM        BFM  -88.068100  30.626801  10  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate dimAirport\n",
    "temp_dimCity_df = dimCity_df.join(dimState_df, dimCity_df.state_id == dimState_df.id, how='inner').select(dimCity_df.id, dimCity_df.name, dimState_df.state_code)\n",
    "airport_window = Window().orderBy(asc('city_id'))\n",
    "dimAirport_df = cleaned_airport_df.join(temp_dimCity_df, [cleaned_airport_df.city==temp_dimCity_df.name, cleaned_airport_df.state==temp_dimCity_df.state_code], how='inner')\\\n",
    "                                  .select(temp_dimCity_df.id.alias('city_id'), cleaned_airport_df.name, col('elevation_ft').alias('elevation'), 'type',\\\n",
    "                                        cleaned_airport_df.id.alias('id_code'), 'gps_code', 'local_code', 'latitude', 'longitude')\\\n",
    "                                  .withColumn('id', row_number().over(airport_window))\n",
    "dimAirport_pd_df = dimAirport_df.toPandas()\n",
    "dimAirport_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Anguilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Antigua-barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Armenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             name\n",
       "0   1      Afghanistan\n",
       "1   2          Albania\n",
       "2   3          Algeria\n",
       "3   4          Andorra\n",
       "4   5           Angola\n",
       "5   6         Anguilla\n",
       "6   7  Antigua-barbuda\n",
       "7   8        Argentina\n",
       "8   9          Armenia\n",
       "9  10            Aruba"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate dimCountry\n",
    "country_window = Window().orderBy(asc('country'))\n",
    "dimCountry_df = country_spark_df.select(row_number().over(country_window).alias('id'),col('country').alias('name'))\n",
    "dimCountry_pd_df = dimCountry_df.toPandas()\n",
    "dimCountry_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa_category</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visa_category  id\n",
       "0      Business   1\n",
       "1      Pleasure   2\n",
       "2       Student   3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate dimVisaCategory\n",
    "dimVisaCategory_df = visa_spark_df.withColumn('id', col('code').cast(Int())).withColumnRenamed('visa_cat', 'visa_category').drop('code')\n",
    "dimVisaCategory_pd_df = dimVisaCategory_df.toPandas()\n",
    "dimVisaCategory_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa_type</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GMB</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GMT</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visa_type  id\n",
       "0        B1   1\n",
       "1        B2   2\n",
       "2        CP   3\n",
       "3       CPL   4\n",
       "4        E1   5\n",
       "5        E2   6\n",
       "6        F1   7\n",
       "7        F2   8\n",
       "8       GMB   9\n",
       "9       GMT  10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate dimVisaType\n",
    "visa_window = Window().orderBy(asc('visa_type'))\n",
    "dimVisaType_df = cleaned_immigration_df.select('visa_type').dropDuplicates().withColumn('id', row_number().over(visa_window))\n",
    "dimVisaType_pd_df = dimVisaType_df.toPandas()\n",
    "dimVisaType_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>residency</th>\n",
       "      <th>destination</th>\n",
       "      <th>cicid</th>\n",
       "      <th>visa_cat_id</th>\n",
       "      <th>visa_type_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1991</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1961</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1959</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1953</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1959</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1970</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1968</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>411.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1964</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  city_id  citizenship  residency  destination  cicid  visa_cat_id  \\\n",
       "0   1    244.0          NaN        246          1.0      7            3   \n",
       "1   2    193.0          2.0          2         23.0     15            2   \n",
       "2   3    411.0          2.0          2         22.0     16            2   \n",
       "3   4    411.0          2.0          2         22.0     17            2   \n",
       "4   5    411.0          2.0          2         23.0     18            1   \n",
       "5   6    411.0          2.0          2         31.0     19            2   \n",
       "6   7    411.0          2.0          2         31.0     20            2   \n",
       "7   8    411.0          2.0          2         33.0     21            2   \n",
       "8   9    411.0          2.0          2         33.0     22            1   \n",
       "9  10    411.0          2.0          2         33.0     23            2   \n",
       "\n",
       "   visa_type_id  year  month  birth_year  age  \n",
       "0             7  2016      4        1991   25  \n",
       "1             2  2016      4        1961   55  \n",
       "2             2  2016      4        1988   28  \n",
       "3             2  2016      4        2012    4  \n",
       "4             1  2016      4        1959   57  \n",
       "5             2  2016      4        1953   63  \n",
       "6             2  2016      4        1959   57  \n",
       "7             2  2016      4        1970   46  \n",
       "8             1  2016      4        1968   48  \n",
       "9             2  2016      4        1964   52  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe to populate factImmigration\n",
    "immigration_window = Window().orderBy(asc('cicid'))\n",
    "factImmigration_df = cleaned_immigration_df.join(dimCountry_df, cleaned_immigration_df.citizenship == dimCountry_df.name, how='left').withColumn('citizenship', col('id')).drop('id','name')\\\n",
    "                                           .join(dimCountry_df, cleaned_immigration_df.residency == dimCountry_df.name, how='left').withColumn('residency', col('id')).drop('id','name')\\\n",
    "                                           .join(dimState_df, cleaned_immigration_df.arrival_state == dimState_df.name, how='left').withColumn('destination', col('id')).drop('id','name','state_code')\\\n",
    "                                           .join(dimVisaCategory_df, cleaned_immigration_df.visa_category == dimVisaCategory_df.visa_category, how='left').withColumn('visa_cat_id', col('id'))\\\n",
    "                                           .drop('id','visa_category')\\\n",
    "                                           .join(dimVisaType_df, cleaned_immigration_df.visa_type == dimVisaType_df.visa_type, how='left').withColumn('visa_type_id', col('id')).drop('id','visa_type')\\\n",
    "                                           .join(temp_dimCity_df, [cleaned_immigration_df.port_city == temp_dimCity_df.name,cleaned_immigration_df.port_state == temp_dimCity_df.state_code], how='left')\\\n",
    "                                           .withColumn('city_id', col('id')).drop('id', 'name', 'state_code')\\\n",
    "                                           .select(row_number().over(immigration_window).alias('id'), 'city_id', 'citizenship', 'residency', 'destination', 'cicid', 'visa_cat_id', 'visa_type_id',\\\n",
    "                                                  'year', 'month', 'birth_year', 'age')                                        \n",
    "#There are over 3 million rows of immigration records, it takes hours to load them into the Redshift cluster. So I took 10,000 records as an example. \n",
    "#If the whole dataset needs to be loaded, please comment out the next line.\n",
    "factImmigration_df = factImmigration_df.filter(col('id')<=10000)\n",
    "\n",
    "factImmigration_pd_df = factImmigration_df.toPandas()\n",
    "factImmigration_pd_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Populate Date into Tables\n",
    "Once the dataframes are created, the to_sql function in pandas can be used to populate the dimension and fact tables on the Redshift cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "redshift_conn = create_engine(f\"postgresql://{USER_NAME}:{PASSWORD}@{CLUSTER_ENDPOINT}:{CLUSTER_PORT}/{DATABASE_NAME}\")\n",
    "dimState_pd_df.to_sql('dimstate', con=redshift_conn, index=False, if_exists='append')\n",
    "dimCity_pd_df.to_sql('dimcity', con=redshift_conn, index=False, if_exists='append')\n",
    "dimTemperature_pd_df.to_sql('dimtemperature', con=redshift_conn, index=False, if_exists='append')\n",
    "dimAirport_pd_df.to_sql('dimairport', con=redshift_conn, index=False, if_exists='append')\n",
    "dimCountry_pd_df.to_sql('dimcountry', con=redshift_conn, index=False, if_exists='append')\n",
    "dimVisaCategory_pd_df.to_sql('dimvisacategory', con=redshift_conn, index=False, if_exists='append')\n",
    "dimVisaType_pd_df.to_sql('dimvisatype', con=redshift_conn, index=False, if_exists='append')\n",
    "factImmigration_pd_df.to_sql('factimmigration', con=redshift_conn, index=False, if_exists='append')\n",
    "redshift_conn.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4 Data Quality Checks\n",
    "After loading dataframes into dimension and fact tables, the number of records in each table will be examined to ensure the data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimState has 49 rows.\n",
      "The dimCity has 596 rows.\n",
      "The dimTemperature has 3132 rows.\n",
      "The dimAirport has 930 rows.\n",
      "The dimCountry has 289 rows.\n",
      "The dimVisaCategory has 3 rows.\n",
      "The dimVisaType has 17 rows.\n",
      "The factImmigration has 10000 rows.\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(f\"host={CLUSTER_ENDPOINT} dbname={DATABASE_NAME} user={USER_NAME} password={PASSWORD} port={CLUSTER_PORT}\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "dimState_count = (\"SELECT 'dimState' AS table_name, COUNT(1) as num_of_records FROM dimstate\")\n",
    "dimCity_count = (\"SELECT 'dimCity' AS table_name, COUNT(1) as num_of_records FROM dimcity\")\n",
    "dimTemperature_count = (\"SELECT 'dimTemperature' AS table_name, COUNT(1) as num_of_records FROM dimtemperature\")\n",
    "dimAirport_count = (\"SELECT 'dimAirport' AS table_name, COUNT(1) as num_of_records FROM dimairport\")\n",
    "dimCountry_count = (\"SELECT 'dimCountry' AS table_name, COUNT(1) as num_of_records FROM dimcountry\")\n",
    "dimVisaCategory_count = (\"SELECT 'dimVisaCategory' AS table_name, COUNT(1) as num_of_records FROM dimvisacategory\")\n",
    "dimVisaType_count  = (\"SELECT 'dimVisaType' AS table_name, COUNT(1) as num_of_records FROM dimvisatype\")\n",
    "factImmigration_count = (\"SELECT 'factImmigration' AS table_name, COUNT(1) as num_of_records FROM factimmigration\")\n",
    "\n",
    "table_count_list = [dimState_count, dimCity_count, dimTemperature_count, dimAirport_count, dimCountry_count, dimVisaCategory_count, dimVisaType_count, factImmigration_count]\n",
    "for query in table_count_list:\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchone()    \n",
    "    print(f\"The {result[0]} has {result[1]} rows.\")\n",
    "    \n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.5 Data dictionary \n",
    "The data dictionary can be used to provide auxiliary information to the dimension and fact tables.\n",
    "##### dimState\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| name | name of state | us-cities-demographics.csv |\n",
    "| state_code | 2-letter code of state |  us-cities-demographics.csv |\n",
    "\n",
    "##### dimCity\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| state_id | id in the dimState | dimState |\n",
    "| name | name of city | us-cities-demographics.csv |\n",
    "| median_age | median age of all residents | us-cities-demographics.csv |\n",
    "| male_population | population of male residents | us-cities-demographics.csv |\n",
    "| female_population | population of female residents | us-cities-demographics.csv |\n",
    "| toal_population | population of all residents | us-cities-demographics.csv |\n",
    "| veteran_population | population of veterans | us-cities-demographics.csv |\n",
    "| average_household_dize | average number of people in a household | us-cities-demographics.csv |\n",
    "\n",
    "##### dimTemperature\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| city_id | id in dimCity, primary key | dimCity |\n",
    "| month | the number of month, primary key | GlobalLandTemperaturesByCity.csv |\n",
    "| temperature | monthly average temperature | us-cities-demographics.csv |\n",
    "\n",
    "##### dimAirport\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| city_id | id in dimCity | dimCity |\n",
    "| name | monthly average temperature | us-cities-demographics.csv |\n",
    "| elevation | elevation of airport in feet | airport-codes_csv.csv |\n",
    "| type | type of airport | airport-codes_csv.csv |\n",
    "| id_code | global identifier of airport | airport-codes_csv.csv |\n",
    "| gps_code | gps identifier of airport | airport-codes_csv.csv |\n",
    "| local_code | loca identifier of airport | airport-codes_csv.csv |\n",
    "| latitude | latitude of airpot | airport-codes_csv.csv |\n",
    "| longitude | longitude of airport | airport-codes_csv.csv |\n",
    "\n",
    "##### dimCountry\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| name | name of country | I94_SAS_Labels_Descriptions.SAS |\n",
    "\n",
    "##### dimVisaCategory\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| visa_category | category of visa | I94_SAS_Labels_Descriptions.SAS |\n",
    "\n",
    "##### dimVisaType\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| visa_type | type of visa | \\*.sas7bdat |\n",
    "\n",
    "##### factImmigration\n",
    "\n",
    "| Column Name | Description | Source |\n",
    "| :--- | :--- | :--- |\n",
    "| id | primary key | auto-incremental |\n",
    "| city_id | id in dimCity | dimCity |\n",
    "| citizenship | id in dimCountry | dimCountry |\n",
    "| residency | id in dimCountry | dimCountry |\n",
    "| detination | id in dimState | dimState |\n",
    "| cicid | unique identifier on I94 Immigration Data | \\*.sas7bdat |\n",
    "| visa_cat_id | id in dimVisaCategory | dimVisaCategory |\n",
    "| visa_type_id | id in dimVisaType | dimVisaType |\n",
    "| year | year of arrival | \\*.sas7bdat |\n",
    "| month | month of arrival | \\*.sas7bdat |\n",
    "| birth_year | year of birth of traveller | \\*.sas7bdat |\n",
    "| age | age of traveller | \\*.sas7bdat |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "1. Clearly state the rationale for the choice of tools and technologies for the project. \\\n",
    "In this project, I used Apache Spark to extract data from files and clean data for loading to the data warehouse. Spark can use a cluster to achieve distributed processing and thus can handel a large amount of data. Besides, Spark use in-memory technology to process data so that it can be used to build high performance data pipeline. The Pandas is used to populate data into Redshift. The reason why I use Pandas is I can not install spark-redshift package that allows Spark to populate date directly to Redshift. However, Pandas uses the in-memory technology so it's still relatively fast. The Redshift cluster is used as the data warehouse due to its high performance in query and easy to set up. \n",
    "2. Propose how often the data should be updated and why.\\\n",
    "Since the time granularity of the dimension and fact table is month, the incremental load should happen every month.\n",
    "3. Write a description of how you would approach the problem differently under the following scenarios:\n",
    " *  The data was increased by 100x.\\\n",
    "Since Spark is easy to scale-out, we can add more nodes to handle data of 100 times larger. In addition, the Redshift cluster also support horizontal scaling, so adding more nodes in Redshift is also a big leap in permance when data size is 100 times larger. \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\\\n",
    "The job scheduler can be used to kick off the data pipeline at flexible schedule, like some time in a day or month. There are plenty of job schedulers in the market, and the most popular two tools are Apache Airflow and OOzie. For exmaple, say it takes one hour to run the data pipeline, we can set the schedule that the job is triggered 1:00 AM every day. If job failed, the job scheduler will send email to notice product support to fix the error, which will ensure the on-time data delivery. \n",
    " * The database needed to be accessed by 100+ people.\\\n",
    "There are two ways to improve the database performance, vertical and horizontal scalling. Vertical scaling means increasing the power of a single database server and horizontal scaling adding more nodes to the database server pool. By comparison, there is limitation on power of the single database server and it's expensive, horizontal scaling has no limitation and cheaper cost. When using cloud computation, both vertical and horizontal scaling are easy to achieve. For example, Redshift provides many tiers of nodes and options of the number of nodes. But from my view, I will apply auto-scaling to the Redshift cluster. As a result, the cluster can adjust its computing power according to the number of requests.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
